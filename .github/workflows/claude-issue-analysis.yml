# yamllint disable rule:line-length
name: Claude Issue Analysis

on:
  issues:
    types: [opened, labeled]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.issue.number }}
  cancel-in-progress: true

jobs:
  analyze:
    # Skip bots, roadmap/pinned issues, and already-analyzed issues
    # For 'labeled' events, only run if 'needs-analysis' label was added
    if: |
      github.actor != 'dependabot[bot]' &&
      github.actor != 'claude[bot]' &&
      !contains(github.event.issue.labels.*.name, 'roadmap') &&
      !contains(github.event.issue.labels.*.name, 'pinned') &&
      !contains(github.event.issue.labels.*.name, 'status:analyzed') &&
      (github.event.action == 'opened' ||
       (github.event.action == 'labeled' && github.event.label.name == 'needs-analysis'))
    runs-on: ubuntu-latest
    # Longer timeout than PR review (10min) since issue analysis is more exploratory -
    # no specific diff to anchor on, must understand problem and explore codebase
    timeout-minutes: 15
    permissions:
      contents: read
      issues: write
      id-token: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 1
          persist-credentials: false

      - name: Analyze issue with Claude
        uses: anthropics/claude-code-action@1b8ee3b94104046d71fde52ec3557651ad8c0d71 # v1.0.29
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          track_progress: true
          prompt: |
            Analyze this issue for the cc-plugin-eval TypeScript evaluation framework.

            ## Issue Context
            - Repository: ${{ github.repository }}
            - Issue #${{ github.event.issue.number }}: ${{ github.event.issue.title }}
            - Author: ${{ github.event.issue.user.login }}
            - Labels: ${{ join(github.event.issue.labels.*.name, ', ') }}

            ## Project Architecture
            cc-plugin-eval is a 4-stage pipeline that evaluates Claude Code plugin component triggering:

            | Stage | Purpose | Key Files |
            |-------|---------|-----------|
            | 1. Analysis | Parse plugin, extract triggers | `src/stages/1-analysis/` |
            | 2. Generation | Create test scenarios | `src/stages/2-generation/` |
            | 3. Execution | Run via Claude Agent SDK | `src/stages/3-execution/` |
            | 4. Evaluation | Detect components, calculate metrics | `src/stages/4-evaluation/` |

            Other key areas:
            - CLI entry: `src/index.ts`
            - Types: `src/types/` (components.ts, state.ts, evaluation.ts, scenario.ts)
            - Config: `src/config/` (Zod validation)
            - State/Resume: `src/state/state-manager.ts`

            ## Instructions

            First, read the issue details:
            ```
            gh issue view ${{ github.event.issue.number }}
            ```

            Then explore the codebase as needed to understand the context. Use `rg` for code search and `Read` for specific files.

            ## Analysis Required

            Provide a structured analysis with these sections:

            ### 1. Problem Assessment
            - Is the problem clearly defined? What information might be missing?
            - What appears to be the root cause or underlying issue?
            - Which stage(s) of the pipeline does this affect?

            ### 2. Proposed Solution(s)
            - Evaluate any solutions mentioned in the issue
            - What are the tradeoffs, risks, and edge cases?
            - Reference specific files/functions that would need changes

            ### 3. Alternative Approaches
            - What other solutions could address this?
            - Compare pros/cons of each approach
            - Consider impact on existing functionality

            ### 4. Implementation Considerations
            - Which files/areas of the codebase would be affected?
            - Any breaking changes or migration concerns?
            - Testing requirements (unit, integration, e2e)?
            - Impact on state/resume capability?

            ### 5. Recommendation
            - Which approach do you recommend and why?
            - Suggested order of implementation steps
            - Any follow-up issues that should be created?

            ## Output

            1. Post your analysis as a comment on the issue:
               ```
               gh issue comment ${{ github.event.issue.number }} --body "YOUR_ANALYSIS"
               ```

            2. After posting the comment, update the labels:
               - Add `status:analyzed` label
               - Remove `needs-analysis` label if present
               ```
               gh issue edit ${{ github.event.issue.number }} --add-label "status:analyzed" --remove-label "needs-analysis"
               ```

            Format the comment with clear markdown headers for each section.
            Reference specific code locations using the pattern `file_path:line_number`.

            If the issue lacks sufficient detail, note what information is needed and add the appropriate label (`status:needs-repro` or `status:needs-design`) instead of `status:analyzed`, but still remove `needs-analysis` if present.
          # Security: Wildcards (:*) are required to pass arguments (e.g., issue number) but are
          # scoped to specific safe subcommands. gh issue view/comment/edit only affect issue
          # metadata (not code), rg/Read/Glob/Grep are read-only. Follows claude-pr-review.yml pattern.
          claude_args: '--allowedTools "Bash(gh issue view:*),Bash(gh issue comment:*),Bash(gh issue edit:*),Bash(rg:*),Read,Glob,Grep"'
